{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 : import libraries\n",
    "\n",
    "# Importing the libraries\n",
    "# to load all the library auro load use these commands\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('data/labeledTrainData.tsv', sep='\\t')\n",
    "print (train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment\n",
       "0  12311_10          0\n",
       "1    8348_2          0\n",
       "2    5828_4          0\n",
       "3    7186_2          0\n",
       "4   12128_7          0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=pd.read_csv('data/sampleSubmission.csv', delimiter=',')\n",
    "print (sample.shape)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# Anlyzing  Train dataset\n",
    "\n",
    "- Sentiment = 0 for IMDB review < 5  ==> Negative \n",
    "\n",
    "\n",
    "- Sentiment =1 for IMDB review >= 7 ===> Positive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Cleaning Function to clear review from stopwords , lemmetizing word , removing puntuation\n",
    "import re\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "lm=WordNetLemmatizer()   # lemmetize for getting the root of word \n",
    "\n",
    "                            # we can also use stem but it slower\n",
    "\n",
    "ps=PorterStemmer()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk import WordNetLemmatizer # to lemmatize words ==> get the root of words\n",
    "\n",
    "def Cleaning(x):\n",
    "    no_punc=' '.join([char for char in x if char not in string.punctuation])\n",
    "    no_punc=re.split('\\W+',no_punc.lower())\n",
    "    no_stop=[word for word in no_punc if word not in stopwords.words('english') ]\n",
    "    tokenized=[lm.lemmatize(word) for word in no_stop]\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "\n",
    "# lemmetize is really slow but more accurate\n",
    "\n",
    "def Clean_Text(x):\n",
    "    no_punc=''.join([char for char in x if char not in string.punctuation])\n",
    "    tokenize=re.findall('[a-zA-Z]+', no_punc.lower())\n",
    "    no_stop=[word for word in tokenize if word not in stopwords.words('english')]\n",
    "    stemm=' '.join([ps.stem(word) for word in no_stop])\n",
    "    return stemm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 35s, sys: 2min 34s, total: 16min 9s\n",
      "Wall time: 16min 16s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>stuff go moment mj ive start listen music watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>classic war world timothi hine entertain film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>film start manag nichola bell give welcom inve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review  \\\n",
       "0  5814_8          1  With all this stuff going down at the moment w...   \n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...   \n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...   \n",
       "\n",
       "                                             cleaned  \n",
       "0  stuff go moment mj ive start listen music watc...  \n",
       "1  classic war world timothi hine entertain film ...  \n",
       "2  film start manag nichola bell give welcom inve...  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time train['cleaned']=train.review.apply(lambda x : Clean_Text(x))\n",
    "\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18750,) (6250,)\n"
     ]
    }
   ],
   "source": [
    "X=train.cleaned\n",
    "y=train.sentiment\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train ,y_test = train_test_split(X,y  ,random_state=1)\n",
    "\n",
    "print (X_train.shape , X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GridSearch to find the best parameters \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "pipline=Pipeline([('vect',TfidfVectorizer()),('nb',MultinomialNB())])\n",
    "\n",
    "\n",
    "\n",
    "params={'vect__analyzer':['word'], 'vect__ngram_range':[(1,1),(1,2)],\n",
    "       'vect__min_df':[0.05,0.01, 0],'vect__max_features':[5000,6000]\n",
    "       }\n",
    "\n",
    "\n",
    "GS=GridSearchCV(pipline,params, cv=5, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...True,\n",
       "        vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'vect__analyzer': ['word'], 'vect__ngram_range': [(1, 1), (1, 2)], 'vect__min_df': [0.05, 0.01, 0], 'vect__max_features': [5000, 6000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8532266666666667"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85824"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vect__analyzer': 'word',\n",
       " 'vect__max_features': 6000,\n",
       " 'vect__min_df': 0,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GridSearch to find the best parameters with RandomForrest \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import  Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "Pipeline=Pipeline([('vect',CountVectorizer()),  ('RF', RandomForestClassifier())])\n",
    "\n",
    "params={ 'vect__ngram_range':[(1,1),(1,2)],\n",
    "       'vect__min_df':[0.05,0.01],'vect__max_features':[4000, 7000],\n",
    "        'RF__criterion':['entropy', 'gini'],'RF__n_estimators':[200] \n",
    "       }\n",
    "\n",
    "Gs=GridSearchCV(Pipeline, params , cv=5 , n_jobs=-1,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.4min\n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.4min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.4min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.4min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.4min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.6min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.6min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.4min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.4min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.4min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.4min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.4min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.4min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  6.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.6min\n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=entropy, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.4min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.6min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.6min\n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.6min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.8min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.8min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.8min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.8min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=4000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.8min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 1), total= 1.4min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.05, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV] RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2) \n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 1), total= 1.5min\n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.7min\n",
      "[CV]  RF__criterion=gini, RF__n_estimators=200, vect__max_features=7000, vect__min_df=0.01, vect__ngram_range=(1, 2), total= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed: 17.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...imators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'vect__ngram_range': [(1, 1), (1, 2)], 'vect__min_df': [0.05, 0.01], 'vect__max_features': [4000, 7000], 'RF__criterion': ['entropy', 'gini'], 'RF__n_estimators': [200]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8361066666666667"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84096"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RF__criterion': 'entropy',\n",
       " 'RF__n_estimators': 200,\n",
       " 'vect__max_features': 7000,\n",
       " 'vect__min_df': 0.01,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>Naturally in a film who's main themes are of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>This movie is a disaster within a disaster fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>All in all, this is a movie for kids. We saw i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>Afraid of the Dark left me with the impression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>A very accurate depiction of small time mob li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review\n",
       "0  12311_10  Naturally in a film who's main themes are of m...\n",
       "1    8348_2  This movie is a disaster within a disaster fil...\n",
       "2    5828_4  All in all, this is a movie for kids. We saw i...\n",
       "3    7186_2  Afraid of the Dark left me with the impression...\n",
       "4   12128_7  A very accurate depiction of small time mob li..."
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv('data/testData.tsv', sep='\\t')\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new cleaning function to not include numbers\n",
    "\n",
    "\n",
    "def Clean_Text(x):\n",
    "    no_punc=''.join([char for char in x if char not in string.punctuation])\n",
    "    tokenize=re.findall('[a-zA-Z]+', no_punc.lower())\n",
    "    no_stop=[word for word in tokenize if word not in stopwords.words('english')]\n",
    "    stemm=' '.join([ps.stem(word) for word in no_stop])\n",
    "    return stemm\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['cleaned']=test.review.apply(lambda x : Clean_Text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>Naturally in a film who's main themes are of m...</td>\n",
       "      <td>natur film who main theme mortal nostalgia los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>This movie is a disaster within a disaster fil...</td>\n",
       "      <td>movi disast within disast film full great acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>All in all, this is a movie for kids. We saw i...</td>\n",
       "      <td>movi kid saw tonight child love one point kid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>Afraid of the Dark left me with the impression...</td>\n",
       "      <td>afraid dark left impress sever differ screenpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>A very accurate depiction of small time mob li...</td>\n",
       "      <td>accur depict small time mob life film new jers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review  \\\n",
       "0  12311_10  Naturally in a film who's main themes are of m...   \n",
       "1    8348_2  This movie is a disaster within a disaster fil...   \n",
       "2    5828_4  All in all, this is a movie for kids. We saw i...   \n",
       "3    7186_2  Afraid of the Dark left me with the impression...   \n",
       "4   12128_7  A very accurate depiction of small time mob li...   \n",
       "\n",
       "                                             cleaned  \n",
       "0  natur film who main theme mortal nostalgia los...  \n",
       "1  movi disast within disast film full great acti...  \n",
       "2  movi kid saw tonight child love one point kid ...  \n",
       "3  afraid dark left impress sever differ screenpl...  \n",
       "4  accur depict small time mob life film new jers...  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=Gs.predict(test.cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment\n",
       "0  12311_10          1\n",
       "1    8348_2          0\n",
       "2    5828_4          1\n",
       "3    7186_2          1\n",
       "4   12128_7          1"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.DataFrame({'id':test.id , 'sentiment':result}, index=None)\n",
    "submission.to_csv('Submission1.csv',  index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2=GS.predict(test.cleaned)\n",
    "submission_2=pd.DataFrame({'id':test.id , 'sentiment':result}, index=None)\n",
    "submission_2.to_csv('Submission2.csv',  index=False)\n",
    "submission_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86112"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# first piple line\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "Pipeline2=make_pipeline(TfidfVectorizer(max_df=0.9 , ngram_range=(1,2),max_features=7000), MultinomialNB())\n",
    "\n",
    "Pipeline2.fit(X_train,y_train)\n",
    "\n",
    "Pipeline2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85472"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first piple line\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "Pipeline1=make_pipeline(TfidfVectorizer(max_features=7000,ngram_range=(1,2)), \n",
    "                        RandomForestClassifier(n_estimators=300 , n_jobs=-1))\n",
    "\n",
    "Pipeline1.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "Pipeline1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment\n",
       "0  12311_10          1\n",
       "1    8348_2          0\n",
       "2    5828_4          1\n",
       "3    7186_2          1\n",
       "4   12128_7          1"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2=Pipeline1.predict(test.cleaned)\n",
    "submission_2=pd.DataFrame({'id':test.id , 'sentiment':result}, index=None)\n",
    "submission_2.to_csv('Submission2.csv',  index=False)\n",
    "submission_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# lets check actual words on good and bad review \n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8528"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer=CountVectorizer(max_df=0.9 , ngram_range=(1,2),max_features=7000)\n",
    "\n",
    "v_X_train=vectorizer.fit_transform(X_train)\n",
    "v_X_test=vectorizer.transform(X_test)\n",
    "\n",
    "nb=MultinomialNB()\n",
    "\n",
    "nb.fit(v_X_train, y_train)\n",
    "nb.score(v_X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>114.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abc</th>\n",
       "      <td>26.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abil</th>\n",
       "      <td>217.0</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abl</th>\n",
       "      <td>391.0</td>\n",
       "      <td>540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abomin</th>\n",
       "      <td>53.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1\n",
       "abandon  114.0  105.0\n",
       "abc       26.0   67.0\n",
       "abil     217.0  184.0\n",
       "abl      391.0  540.0\n",
       "abomin    53.0   11.0"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "features=vectorizer.get_feature_names()\n",
    "\n",
    "words=pd.DataFrame(nb.feature_count_.T, index=features)\n",
    "\n",
    "words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative_Sentiment</th>\n",
       "      <th>postive_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>114.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abc</th>\n",
       "      <td>26.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abil</th>\n",
       "      <td>217.0</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abl</th>\n",
       "      <td>391.0</td>\n",
       "      <td>540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abomin</th>\n",
       "      <td>53.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         negative_Sentiment  postive_sentiment\n",
       "abandon               114.0              105.0\n",
       "abc                    26.0               67.0\n",
       "abil                  217.0              184.0\n",
       "abl                   391.0              540.0\n",
       "abomin                 53.0               11.0"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or featur_count give us number of words in each sentiment \n",
    "\n",
    "# nb.feature_count_[0,:]  # for sentiment 0\n",
    "# nb.feature_count_[1,:] # for sentiment 1\n",
    "\n",
    "\n",
    "Words=pd.DataFrame({'negative_Sentiment':nb.feature_count_[0,:], 'postive_sentiment':nb.feature_count_[1,:]}, index=features)\n",
    "Words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative_Sentiment</th>\n",
       "      <th>postive_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>br</th>\n",
       "      <td>22283.0</td>\n",
       "      <td>20920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movi</th>\n",
       "      <td>20785.0</td>\n",
       "      <td>16431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>16308.0</td>\n",
       "      <td>18536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>9580.0</td>\n",
       "      <td>10427.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>9006.0</td>\n",
       "      <td>7626.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      negative_Sentiment  postive_sentiment\n",
       "br               22283.0            20920.0\n",
       "movi             20785.0            16431.0\n",
       "film             16308.0            18536.0\n",
       "one               9580.0            10427.0\n",
       "like              9006.0             7626.0"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we have the words we can sort them\n",
    "\n",
    "Words.sort_values(by='negative_Sentiment', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative_Sentiment</th>\n",
       "      <th>postive_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>br</th>\n",
       "      <td>22283.0</td>\n",
       "      <td>20920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>16308.0</td>\n",
       "      <td>18536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movi</th>\n",
       "      <td>20785.0</td>\n",
       "      <td>16431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>9580.0</td>\n",
       "      <td>10427.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>9006.0</td>\n",
       "      <td>7626.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      negative_Sentiment  postive_sentiment\n",
       "br               22283.0            20920.0\n",
       "film             16308.0            18536.0\n",
       "movi             20785.0            16431.0\n",
       "one               9580.0            10427.0\n",
       "like              9006.0             7626.0"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Words.sort_values(by='postive_sentiment', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative_Sentiment</th>\n",
       "      <th>postive_sentiment</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boll</th>\n",
       "      <td>118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thunderbird</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uwe</th>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uwe boll</th>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act horribl</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beowulf</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prom night</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seagal</th>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst film</th>\n",
       "      <td>241.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total wast</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>br worst</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour life</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one worst</th>\n",
       "      <td>356.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor act</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piec garbag</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             negative_Sentiment  postive_sentiment     Percent\n",
       "boll                      118.0                0.0         inf\n",
       "thunderbird                65.0                0.0         inf\n",
       "uwe                        86.0                0.0         inf\n",
       "uwe boll                   73.0                0.0         inf\n",
       "act horribl                54.0                0.0         inf\n",
       "beowulf                    50.0                0.0         inf\n",
       "prom night                 53.0                0.0         inf\n",
       "seagal                    110.0                1.0  110.000000\n",
       "worst film                241.0                3.0   80.333333\n",
       "total wast                 67.0                1.0   67.000000\n",
       "br worst                   62.0                1.0   62.000000\n",
       "hour life                  60.0                1.0   60.000000\n",
       "one worst                 356.0                7.0   50.857143\n",
       "poor act                   50.0                1.0   50.000000\n",
       "piec garbag                46.0                1.0   46.000000"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or we can create a new columns and compare words on both\n",
    "\n",
    "\n",
    "Words['Percent']=Words.negative_Sentiment / Words.postive_sentiment\n",
    "\n",
    "Words.sort_values(by='Percent', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative_Sentiment</th>\n",
       "      <th>postive_sentiment</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mathieu</th>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red sox</th>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>din</th>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antwon</th>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goldsworthi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rob roy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.013158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edi</th>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nanci drew</th>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.018519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matthau</th>\n",
       "      <td>2.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.019048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polic stori</th>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sg</th>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gundam</th>\n",
       "      <td>2.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.024096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sox</th>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polanski</th>\n",
       "      <td>3.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.035294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kolchak</th>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.040541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             negative_Sentiment  postive_sentiment   Percent\n",
       "mathieu                     0.0               49.0  0.000000\n",
       "red sox                     0.0               49.0  0.000000\n",
       "din                         0.0               49.0  0.000000\n",
       "antwon                      0.0               63.0  0.000000\n",
       "goldsworthi                 0.0               52.0  0.000000\n",
       "rob roy                     1.0               76.0  0.013158\n",
       "edi                         1.0               63.0  0.015873\n",
       "nanci drew                  1.0               54.0  0.018519\n",
       "matthau                     2.0              105.0  0.019048\n",
       "polic stori                 1.0               48.0  0.020833\n",
       "sg                          1.0               47.0  0.021277\n",
       "gundam                      2.0               83.0  0.024096\n",
       "sox                         2.0               62.0  0.032258\n",
       "polanski                    3.0               85.0  0.035294\n",
       "kolchak                     3.0               74.0  0.040541"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Words.sort_values(by='Percent').head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
